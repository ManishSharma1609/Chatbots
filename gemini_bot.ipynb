{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGgrDCN2ys8H"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oalUqzkryuUl"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd01IEI8yz0c"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "#dotenv package to load the API key\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkoZu14ay0xQ"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=userdata.get('GeminiProKey')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6143dXzzvli"
      },
      "outputs": [],
      "source": [
        "#Create a new .env file in the workspace and store the API key in it\n",
        "!echo -e 'GOOGLE_API_KEY=XXXXXXXXXXXXXXXXXXXXXX' > .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6RtjnFMzOvF"
      },
      "outputs": [],
      "source": [
        "!ls -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZzOLfrUzoYf"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvOLlhmG4-kE"
      },
      "outputs": [],
      "source": [
        "#Create a helper function that will convert the markdown into nicely formatted text\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢','*')\n",
        "  return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQk-LYuv5Jkv"
      },
      "outputs": [],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yHRsAit5c_K"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71VkGJS9BeX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"What is the meaning of life?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrU3XljI9FX1"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYIYKNIf9GdT"
      },
      "outputs": [],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7LLbUSi9OY8"
      },
      "outputs": [],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxv8P8VS0c58"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvq_M6yb0g7R"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TGuDWBm0iqq"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(\"What is Mean Average Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fWEvJwA0kag"
      },
      "outputs": [],
      "source": [
        "to_markdown(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3dXPWA60m57"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct-M0mc80w9s"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEIECly601Sf"
      },
      "outputs": [],
      "source": [
        "!mkdir pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_p0FtQs04qu"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "data = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn49VJFo1XPF"
      },
      "outputs": [],
      "source": [
        "print(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB3fTrU21ZsX"
      },
      "outputs": [],
      "source": [
        "context = \"\\n\".join(str(p.page_content) for p in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdsRMt0Z1d0j"
      },
      "outputs": [],
      "source": [
        "print(\"The total number of words in the context:\", len(context))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3IqYHCI1ggU"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIndPmmG1nHP"
      },
      "outputs": [],
      "source": [
        "texts = text_splitter.split_text(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93WVMqpL1oIj"
      },
      "outputs": [],
      "source": [
        "print(len(texts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u1OlPb71p-J"
      },
      "outputs": [],
      "source": [
        "texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF9qTQFu1tHm"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM-VOrsu1vh_"
      },
      "outputs": [],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrLvTpIF1xYK"
      },
      "outputs": [],
      "source": [
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_XiQsvX1zHY"
      },
      "outputs": [],
      "source": [
        "question = \"What are oppertunities and challenges for machine learning in material science\"\n",
        "docs = vector_index.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Y_lHVh2GFl"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibpZRHYD2IuH"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "  Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
        "  provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "  Context:\\n {context}?\\n\n",
        "  Question: \\n{question}\\n\n",
        "\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unlpm7Dv2M4l"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcCTv4C52QAz"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ilm74Lm2R5J"
      },
      "outputs": [],
      "source": [
        "response = chain(\n",
        "    {\"input_documents\":docs, \"question\": question}\n",
        "    , return_only_outputs=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU49O0eO2Try"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKGppVdr2WMn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
